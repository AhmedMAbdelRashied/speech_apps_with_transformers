{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30747,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Fine-tuning SpeechT5",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "vt2w-DCGdLb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning SpeechT5\n"
      ],
      "metadata": {
        "id": "3yo7yORKdLb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets soundfile speechbrain accelerate\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-11T20:36:17.979035Z",
          "iopub.execute_input": "2024-07-11T20:36:17.979988Z",
          "iopub.status.idle": "2024-07-11T20:36:32.657735Z",
          "shell.execute_reply.started": "2024-07-11T20:36:17.979941Z",
          "shell.execute_reply": "2024-07-11T20:36:32.656698Z"
        },
        "trusted": true,
        "id": "ZoxdDih5dLb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!python -c \"from huggingface_hub.hf_api import HfFolder; HfFolder.save_token('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')\"\n",
        "!huggingface-cli whoami"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-11T20:36:32.659524Z",
          "iopub.execute_input": "2024-07-11T20:36:32.659823Z",
          "iopub.status.idle": "2024-07-11T20:36:35.755059Z",
          "shell.execute_reply.started": "2024-07-11T20:36:32.659795Z",
          "shell.execute_reply": "2024-07-11T20:36:35.753834Z"
        },
        "trusted": true,
        "id": "lCZJ1Oy3dLcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The dataset\n",
        "For this example we’ll take the Dutch (nl) language subset of the VoxPopuli dataset. VoxPopuli is a large-scale multilingual speech corpus consisting of data sourced from 2009-2020 European Parliament event recordings. It contains labelled audio-transcription data for 15 European languages. While we will be using the Dutch language subset\n",
        "\n",
        "This is an automated speech recognition (ASR) dataset, so, as mentioned before, it is not the most suitable option for training TTS models. However, it will be good enough for this exercise.\n",
        "\n",
        "Let’s load the data:"
      ],
      "metadata": {
        "id": "G835qXlNdLcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, Audio\n",
        "\n",
        "dataset = load_dataset(\"facebook/voxpopuli\",\n",
        "                       \"nl\", split=\"train\",\n",
        "                      trust_remote_code=True\n",
        "                      )\n",
        "len(dataset)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-11T20:36:35.756618Z",
          "iopub.execute_input": "2024-07-11T20:36:35.75699Z",
          "iopub.status.idle": "2024-07-11T20:46:03.121342Z",
          "shell.execute_reply.started": "2024-07-11T20:36:35.756953Z",
          "shell.execute_reply": "2024-07-11T20:46:03.120498Z"
        },
        "trusted": true,
        "id": "C5ZSTL1AdLcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "20968 examples should be sufficient for fine-tuning. SpeechT5 expects audio data to have a sampling rate of 16 kHz, so make sure the examples in the dataset meet this requirement:"
      ],
      "metadata": {
        "id": "X6RTFaOYdLcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=dataset.cast_column('audio',Audio(sampling_rate=16000))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-11T20:46:03.123475Z",
          "iopub.execute_input": "2024-07-11T20:46:03.123759Z",
          "iopub.status.idle": "2024-07-11T20:46:03.132962Z",
          "shell.execute_reply.started": "2024-07-11T20:46:03.123733Z",
          "shell.execute_reply": "2024-07-11T20:46:03.132055Z"
        },
        "trusted": true,
        "id": "GjRskLxYdLcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing the data\n"
      ],
      "metadata": {
        "id": "qFXyrAXcdLcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import SpeechT5Processor\n",
        "checkpoint = \"microsoft/speecht5_tts\"\n",
        "processor = SpeechT5Processor.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-11T20:46:03.134183Z",
          "iopub.execute_input": "2024-07-11T20:46:03.134457Z",
          "iopub.status.idle": "2024-07-11T20:46:11.806098Z",
          "shell.execute_reply.started": "2024-07-11T20:46:03.134434Z",
          "shell.execute_reply": "2024-07-11T20:46:11.805147Z"
        },
        "trusted": true,
        "id": "aCTkOrXbdLcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, for preparing the text, we’ll need the tokenizer part of the processor, so let’s get it:\n",
        "\n"
      ],
      "metadata": {
        "id": "sp383slDdLcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = processor.tokenizer\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-11T20:46:11.807501Z",
          "iopub.execute_input": "2024-07-11T20:46:11.808436Z",
          "iopub.status.idle": "2024-07-11T20:46:11.812431Z",
          "shell.execute_reply.started": "2024-07-11T20:46:11.808407Z",
          "shell.execute_reply": "2024-07-11T20:46:11.811385Z"
        },
        "trusted": true,
        "id": "J9vaExoadLcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-11T20:46:11.813537Z",
          "iopub.execute_input": "2024-07-11T20:46:11.813801Z",
          "iopub.status.idle": "2024-07-11T20:46:23.852332Z",
          "shell.execute_reply.started": "2024-07-11T20:46:11.813778Z",
          "shell.execute_reply": "2024-07-11T20:46:23.851491Z"
        },
        "trusted": true,
        "id": "AsOtOp-udLcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 'accent': 'None'}\n",
        "What you may notice is that the dataset examples contain raw_text and normalized_text features. When deciding which feature to use as the text input, it will be important to know that the SpeechT5 tokenizer doesn’t have any tokens for numbers. In normalized_text the numbers are written out as text. Thus, it is a better fit, and we should use normalized_text as input text.\n",
        "\n",
        "Because SpeechT5 was trained on the English language, it may not recognize certain characters in the Dutch dataset. If left as is, these characters will be converted to <unk> tokens. However, in Dutch, certain characters like à are used to stress syllables. In order to preserve the meaning of the text, we can replace this character with a regular a.\n",
        "\n",
        "To identify unsupported tokens, extract all unique characters in the dataset using the SpeechT5Tokenizer which works with characters as tokens. To do this, we’ll write the extract_all_chars mapping function that concatenates the transcriptions from all examples into one string and converts it to a set of characters. Make sure to set batched=True and batch_size=-1 in dataset.map() so that all transcriptions are available at once for the mapping function.\n",
        "\n"
      ],
      "metadata": {
        "id": "qhJ0UNt7dLcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_all_chars(batch):\n",
        "    all_text=\" \".join(batch['normalized_text'])\n",
        "    vocab=list(set(all_text))\n",
        "    return {\"vocab\": [vocab], \"all_text\": [all_text]}\n",
        "\n",
        "vocabs=dataset.map(\n",
        "    extract_all_chars,\n",
        "    batched=True,\n",
        "    batch_size=-1,\n",
        "    keep_in_memory=True,\n",
        "    remove_columns=dataset.column_names,\n",
        ")\n",
        "\n",
        "dataset_vocab = set(vocabs[\"vocab\"][0])\n",
        "tokenizer_vocab = {k for k, _ in tokenizer.get_vocab().items()}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-11T20:46:23.853387Z",
          "iopub.execute_input": "2024-07-11T20:46:23.853868Z",
          "iopub.status.idle": "2024-07-11T20:46:23.968877Z",
          "shell.execute_reply.started": "2024-07-11T20:46:23.853842Z",
          "shell.execute_reply": "2024-07-11T20:46:23.968169Z"
        },
        "trusted": true,
        "id": "rzCAJtpCdLcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_vocab - tokenizer_vocab\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-11T20:46:23.969878Z",
          "iopub.execute_input": "2024-07-11T20:46:23.970179Z",
          "iopub.status.idle": "2024-07-11T20:46:23.976573Z",
          "shell.execute_reply.started": "2024-07-11T20:46:23.970154Z",
          "shell.execute_reply": "2024-07-11T20:46:23.975775Z"
        },
        "trusted": true,
        "id": "7r0GWNk5dLcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replacements = [\n",
        "    (\"à\", \"a\"),\n",
        "    (\"ç\", \"c\"),\n",
        "    (\"è\", \"e\"),\n",
        "    (\"ë\", \"e\"),\n",
        "    (\"í\", \"i\"),\n",
        "    (\"ï\", \"i\"),\n",
        "    (\"ö\", \"o\"),\n",
        "    (\"ü\", \"u\"),\n",
        "]\n",
        "\n",
        "def cleanup_text(inputs):\n",
        "    for src , dst in replacements:\n",
        "        inputs[\"normalized_text\"] = inputs[\"normalized_text\"].replace(src, dst)\n",
        "    return inputs\n",
        "\n",
        "dataset=dataset.map(cleanup_text)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-11T20:46:23.9802Z",
          "iopub.execute_input": "2024-07-11T20:46:23.980466Z",
          "iopub.status.idle": "2024-07-11T20:46:27.305604Z",
          "shell.execute_reply.started": "2024-07-11T20:46:23.980443Z",
          "shell.execute_reply": "2024-07-11T20:46:27.30484Z"
        },
        "trusted": true,
        "id": "tGRe-B7fdLcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Speakers\n",
        "The VoxPopuli dataset includes speech from multiple speakers, but how many speakers are represented in the dataset? To determine this, we can count the number of unique speakers and the number of examples each speaker contributes to the dataset. With a total of 20,968 examples in the dataset, this information will give us a better understanding of the distribution of speakers and examples in the data."
      ],
      "metadata": {
        "id": "_qUMQy8-dLcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "speaker_counts = defaultdict(int)\n",
        "\n",
        "for speaker_id in dataset[\"speaker_id\"]:\n",
        "    speaker_counts[speaker_id] += 1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-11T20:46:27.306667Z",
          "iopub.execute_input": "2024-07-11T20:46:27.30698Z",
          "iopub.status.idle": "2024-07-11T20:46:27.346867Z",
          "shell.execute_reply.started": "2024-07-11T20:46:27.306954Z",
          "shell.execute_reply": "2024-07-11T20:46:27.346203Z"
        },
        "trusted": true,
        "id": "-UTq_StndLcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "plt.hist(speaker_counts.values(), bins=20)\n",
        "plt.ylabel(\"Speakers\")\n",
        "plt.xlabel(\"Examples\")\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-11T20:46:27.347793Z",
          "iopub.execute_input": "2024-07-11T20:46:27.348054Z",
          "iopub.status.idle": "2024-07-11T20:46:27.639174Z",
          "shell.execute_reply.started": "2024-07-11T20:46:27.348031Z",
          "shell.execute_reply": "2024-07-11T20:46:27.638287Z"
        },
        "trusted": true,
        "id": "xHRPi0-5dLcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The histogram reveals that approximately one-third of the speakers in the dataset have fewer than 100 examples, while around ten speakers have more than 500 examples. To improve training efficiency and balance the dataset, we can limit the data to speakers with between 100 and 400 examples."
      ],
      "metadata": {
        "id": "bel0M3UKdLcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def select_speaker(speaker_id):\n",
        "    return 100 <= speaker_counts[speaker_id] <= 400\n",
        "\n",
        "\n",
        "dataset = dataset.filter(select_speaker, input_columns=[\"speaker_id\"])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-11T20:46:27.640463Z",
          "iopub.execute_input": "2024-07-11T20:46:27.640817Z",
          "iopub.status.idle": "2024-07-11T20:46:27.734788Z",
          "shell.execute_reply.started": "2024-07-11T20:46:27.640782Z",
          "shell.execute_reply": "2024-07-11T20:46:27.733951Z"
        },
        "trusted": true,
        "id": "VNGk1bCRdLcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Speaker embeddings\n"
      ],
      "metadata": {
        "id": "p5YByf70dLcO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Speaker embeddings\n",
        "To enable the TTS model to differentiate between multiple speakers, you’ll need to create a speaker embedding for each example. The speaker embedding is an additional input into the model that captures a particular speaker’s voice characteristics. To generate these speaker embeddings, use the pre-trained spkrec-xvect-voxceleb model from SpeechBrain.\n",
        "\n",
        "Create a function create_speaker_embedding() that takes an input audio waveform and outputs a 512-element vector containing the corresponding speaker embedding.\n",
        "\n"
      ],
      "metadata": {
        "id": "pZ28N6DndLcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/speechbrain/speechbrain.git@develop\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-11T20:46:27.735777Z",
          "iopub.execute_input": "2024-07-11T20:46:27.736052Z",
          "iopub.status.idle": "2024-07-11T20:46:57.906526Z",
          "shell.execute_reply.started": "2024-07-11T20:46:27.736028Z",
          "shell.execute_reply": "2024-07-11T20:46:57.905509Z"
        },
        "trusted": true,
        "id": "YHuYtLi9dLcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "from speechbrain.inference.speaker import EncoderClassifier\n",
        "\n",
        "spk_model_name = \"speechbrain/spkrec-xvect-voxceleb\"\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "speaker_model = EncoderClassifier.from_hparams(\n",
        "    source=spk_model_name,\n",
        "    run_opts={\"device\": device},\n",
        "    savedir=os.path.join(\"/tmp\", spk_model_name),\n",
        ")\n",
        "\n",
        "\n",
        "def create_speaker_embedding(waveform):\n",
        "    with torch.no_grad():\n",
        "        speaker_embeddings = speaker_model.encode_batch(torch.tensor(waveform))\n",
        "        speaker_embeddings = torch.nn.functional.normalize(speaker_embeddings, dim=2)\n",
        "        speaker_embeddings = speaker_embeddings.squeeze().cpu().numpy()\n",
        "    return speaker_embeddings\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-11T20:46:57.90805Z",
          "iopub.execute_input": "2024-07-11T20:46:57.908374Z",
          "iopub.status.idle": "2024-07-11T20:47:07.015705Z",
          "shell.execute_reply.started": "2024-07-11T20:46:57.908343Z",
          "shell.execute_reply": "2024-07-11T20:47:07.014931Z"
        },
        "trusted": true,
        "id": "gpr-g4kFdLcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It’s important to note that the speechbrain/spkrec-xvect-voxceleb model was trained on English speech from the VoxCeleb dataset, whereas the training examples in this guide are in Dutch. While we believe that this model will still generate reasonable speaker embeddings for our Dutch dataset, this assumption may not hold true in all cases.\n",
        "\n",
        "For optimal results, we would need to train an X-vector model on the target speech first. This will ensure that the model is better able to capture the unique voice characteristics present in the Dutch language. If you’d like to train your own X-vector model,\n",
        "\n",
        "If you’d like to train your own X-vector model, you can use [this script](https://huggingface.co/mechanicalsea/speecht5-vc/blob/main/manifest/utils/prep_cmu_arctic_spkemb.py) as an example"
      ],
      "metadata": {
        "id": "5wh-G9BHdLcP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Irgr80C1dLcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(example):\n",
        "    audio = example[\"audio\"]\n",
        "\n",
        "    example = processor(\n",
        "        text=example[\"normalized_text\"],\n",
        "        audio_target=audio[\"array\"],\n",
        "        sampling_rate=audio[\"sampling_rate\"],\n",
        "        return_attention_mask=False,\n",
        "    )\n",
        "\n",
        "    # strip off the batch dimension\n",
        "    example[\"labels\"] = example[\"labels\"][0]\n",
        "\n",
        "    # use SpeechBrain to obtain x-vector\n",
        "    example[\"speaker_embeddings\"] = create_speaker_embedding(audio[\"array\"])\n",
        "\n",
        "    return example"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-11T20:47:07.016805Z",
          "iopub.execute_input": "2024-07-11T20:47:07.017088Z",
          "iopub.status.idle": "2024-07-11T20:47:07.022882Z",
          "shell.execute_reply.started": "2024-07-11T20:47:07.017064Z",
          "shell.execute_reply": "2024-07-11T20:47:07.021969Z"
        },
        "trusted": true,
        "id": "dddgZPypdLcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.map(prepare_dataset, remove_columns=dataset.column_names)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-11T20:47:07.024081Z",
          "iopub.execute_input": "2024-07-11T20:47:07.024345Z",
          "iopub.status.idle": "2024-07-11T20:54:46.456552Z",
          "shell.execute_reply.started": "2024-07-11T20:47:07.024322Z",
          "shell.execute_reply": "2024-07-11T20:54:46.455597Z"
        },
        "trusted": true,
        "id": "_kcukmQgdLcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You’ll see a warning saying that some examples in the dataset are longer than the maximum input length the model can handle (600 tokens). Remove those examples from the dataset. Here we go even further and to allow for larger batch sizes we remove anything over 200 tokens."
      ],
      "metadata": {
        "id": "8SZUbBG-dLcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_not_too_long(input_ids):\n",
        "    input_length = len(input_ids)\n",
        "    return input_length < 200\n",
        "\n",
        "\n",
        "dataset = dataset.filter(is_not_too_long, input_columns=[\"input_ids\"])\n",
        "len(dataset)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-11T20:54:46.457835Z",
          "iopub.execute_input": "2024-07-11T20:54:46.458495Z",
          "iopub.status.idle": "2024-07-11T20:54:47.328061Z",
          "shell.execute_reply.started": "2024-07-11T20:54:46.458468Z",
          "shell.execute_reply": "2024-07-11T20:54:47.327231Z"
        },
        "trusted": true,
        "id": "wAtncHANdLcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, create a basic train/test split:\n",
        "\n"
      ],
      "metadata": {
        "id": "xUzyioGAdLcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.train_test_split(test_size=0.1)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-11T20:54:47.329191Z",
          "iopub.execute_input": "2024-07-11T20:54:47.329449Z",
          "iopub.status.idle": "2024-07-11T20:54:47.353536Z",
          "shell.execute_reply.started": "2024-07-11T20:54:47.329428Z",
          "shell.execute_reply": "2024-07-11T20:54:47.352564Z"
        },
        "trusted": true,
        "id": "jYf9yOgbdLcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Union\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class TTSDataCollatorWithPadding:\n",
        "    processor: Any\n",
        "\n",
        "    def __call__(\n",
        "        self, features: List[Dict[str, Union[List[int], torch.Tensor]]]\n",
        "    ) -> Dict[str, torch.Tensor]:\n",
        "\n",
        "        input_ids = [{\"input_ids\": feature[\"input_ids\"]} for feature in features]\n",
        "\n",
        "        label_features = [{\"input_values\": feature[\"labels\"]} for feature in features]\n",
        "\n",
        "        speaker_features = [feature[\"speaker_embeddings\"] for feature in features]\n",
        "\n",
        "        # collate the inputs and targets into a batch\n",
        "        batch = processor.pad(\n",
        "            input_ids=input_ids, labels=label_features, return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # replace padding with -100 to ignore loss correctly\n",
        "        batch[\"labels\"] = batch[\"labels\"].masked_fill(\n",
        "            batch.decoder_attention_mask.unsqueeze(-1).ne(1), -100\n",
        "        )\n",
        "\n",
        "        # not used during fine-tuning\n",
        "        del batch[\"decoder_attention_mask\"]\n",
        "\n",
        "        # round down target lengths to multiple of reduction factor\n",
        "        if model.config.reduction_factor > 1:\n",
        "            target_lengths = torch.tensor(\n",
        "                [len(feature[\"input_values\"]) for feature in label_features]\n",
        "            )\n",
        "            target_lengths = target_lengths.new(\n",
        "                [\n",
        "                    length - length % model.config.reduction_factor\n",
        "                    for length in target_lengths\n",
        "                ]\n",
        "            )\n",
        "            max_length = max(target_lengths)\n",
        "            batch[\"labels\"] = batch[\"labels\"][:, :max_length]\n",
        "\n",
        "        # also add in the speaker embeddings\n",
        "        batch[\"speaker_embeddings\"] = torch.tensor(speaker_features)\n",
        "\n",
        "        return batch"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-11T20:54:47.355694Z",
          "iopub.execute_input": "2024-07-11T20:54:47.356365Z",
          "iopub.status.idle": "2024-07-11T20:54:47.366414Z",
          "shell.execute_reply.started": "2024-07-11T20:54:47.35634Z",
          "shell.execute_reply": "2024-07-11T20:54:47.365456Z"
        },
        "trusted": true,
        "id": "g_Qr4c9UdLcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In SpeechT5, the input to the decoder part of the model is reduced by a factor 2. In other words, it throws away every other timestep from the target sequence. The decoder then predicts a sequence that is twice as long. Since the original target sequence length may be odd, the data collator makes sure to round the maximum length of the batch down to be a multiple of 2."
      ],
      "metadata": {
        "id": "2QNOCRgXdLcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = TTSDataCollatorWithPadding(processor=processor)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-11T20:54:47.367474Z",
          "iopub.execute_input": "2024-07-11T20:54:47.36773Z",
          "iopub.status.idle": "2024-07-11T20:54:47.379439Z",
          "shell.execute_reply.started": "2024-07-11T20:54:47.367707Z",
          "shell.execute_reply": "2024-07-11T20:54:47.37855Z"
        },
        "trusted": true,
        "id": "DuM92Xv2dLcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model\n",
        "Load the pre-trained model from the same checkpoint as you used for loading the processor:\n",
        "\n"
      ],
      "metadata": {
        "id": "ceCkAUIbdLcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import SpeechT5ForTextToSpeech\n",
        "\n",
        "model = SpeechT5ForTextToSpeech.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-11T20:54:47.380439Z",
          "iopub.execute_input": "2024-07-11T20:54:47.380697Z",
          "iopub.status.idle": "2024-07-11T20:54:56.422043Z",
          "shell.execute_reply.started": "2024-07-11T20:54:47.380675Z",
          "shell.execute_reply": "2024-07-11T20:54:56.421032Z"
        },
        "trusted": true,
        "id": "9v7sb22NdLcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "\n",
        "# disable cache during training since it's incompatible with gradient checkpointing\n",
        "model.config.use_cache = False\n",
        "\n",
        "# set language and task for generation and re-enable cache\n",
        "model.generate = partial(model.generate, use_cache=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-11T20:54:56.423233Z",
          "iopub.execute_input": "2024-07-11T20:54:56.423532Z",
          "iopub.status.idle": "2024-07-11T20:54:56.428365Z",
          "shell.execute_reply.started": "2024-07-11T20:54:56.423505Z",
          "shell.execute_reply": "2024-07-11T20:54:56.427464Z"
        },
        "trusted": true,
        "id": "V6BLcnGldLce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"ahmedabdelrashied/speecht5_finetuned\",\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=8,\n",
        "    learning_rate=1e-5,\n",
        "    warmup_steps=500,\n",
        "    max_steps=4000,\n",
        "    gradient_checkpointing=True,\n",
        "    fp16=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    per_device_eval_batch_size=2,\n",
        "    save_steps=1000,\n",
        "    eval_steps=1000,\n",
        "    logging_steps=25,\n",
        "    report_to=[\"tensorboard\"],\n",
        "    load_best_model_at_end=True,\n",
        "    greater_is_better=False,\n",
        "    label_names=[\"labels\"],\n",
        "    push_to_hub=True,\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-11T20:54:56.429795Z",
          "iopub.execute_input": "2024-07-11T20:54:56.430145Z",
          "iopub.status.idle": "2024-07-11T20:54:56.492836Z",
          "shell.execute_reply.started": "2024-07-11T20:54:56.430115Z",
          "shell.execute_reply": "2024-07-11T20:54:56.491934Z"
        },
        "trusted": true,
        "id": "23feucwbdLcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    args=training_args,\n",
        "    model=model,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=processor,\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-11T20:54:56.494174Z",
          "iopub.execute_input": "2024-07-11T20:54:56.49451Z",
          "iopub.status.idle": "2024-07-11T20:54:57.552493Z",
          "shell.execute_reply.started": "2024-07-11T20:54:56.494481Z",
          "shell.execute_reply": "2024-07-11T20:54:57.55157Z"
        },
        "trusted": true,
        "id": "4O5HBnPKdLcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-11T20:54:57.553604Z",
          "iopub.execute_input": "2024-07-11T20:54:57.553885Z"
        },
        "trusted": true,
        "id": "coYMd6cldLcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub()"
      ],
      "metadata": {
        "trusted": true,
        "id": "jcLWzJ5odLcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference\n"
      ],
      "metadata": {
        "id": "NDDJIU8jdLch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SpeechT5ForTextToSpeech.from_pretrained(\n",
        "    \"ahmedabdelrashied/speecht5_finetuned\"\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "fLRn7tHcdLch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = dataset[\"test\"][304]\n",
        "speaker_embeddings = torch.tensor(example[\"speaker_embeddings\"]).unsqueeze(0"
      ],
      "metadata": {
        "trusted": true,
        "id": "l7KNr7i4dLch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"hallo allemaal, ik praat nederlands. groetjes aan iedereen!\"\n",
        "inputs = processor(text=text, return_tensors=\"pt\")\n",
        "from transformers import SpeechT5HifiGan\n",
        "\n",
        "vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")\n",
        "speech = model.generate_speech(inputs[\"input_ids\"], speaker_embeddings, vocoder=vocoder)\n",
        "from IPython.display import Audio\n",
        "\n",
        "Audio(speech.numpy(), rate=16000)"
      ],
      "metadata": {
        "trusted": true,
        "id": "_FcdR_mJdLci"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}